{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "mount_file_id": "1tO572V-oVzGMbq1ftr3Xa_BjUpBi1a8F",
      "authorship_tag": "ABX9TyMGFpwUlIqGiaOtO+ud8348",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e-olang/Computer-Vision/blob/main/Mkulima/Rice%20Leaf/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t9s_gCN7zK0",
        "outputId": "3a08dbee-401e-478e-88c8-0b69b6e66cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Rice Leaf\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Rice Leaf/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDKecF_X8XDg",
        "outputId": "984d3e88-f991-47f4-c5e0-9cbc5aa9b16b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AccVal_acc.png  kaggle.json       model_CNN.h5       \u001b[0m\u001b[01;34mRiceLeafs\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/           LossVal_loss.png  model_resnet50.h5  riceleafs.zip\n",
            "\u001b[01;34mflagged\u001b[0m/        model_CNN_2.h5    notebook.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '/content/drive/MyDrive/Colab Notebooks/Rice Leaf/RiceLeafs/train'\n",
        "# '/content/drive/MyDrive/Colab Notebooks/Rice Leaf/RiceLeafs/validation'"
      ],
      "metadata": {
        "id": "6wjfIfwbjee3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### modeling"
      ],
      "metadata": {
        "id": "wVou_1T2JQFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "ex41sJuUjp4E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path('RiceLeafs/train')"
      ],
      "metadata": {
        "id": "qKfZWUHRkK5G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "9eJIrCSYkb-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "img_height = 360\n",
        "img_width = 360"
      ],
      "metadata": {
        "id": "5gJKlLhLkpih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.1,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ufouuUTGkucm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "hM2BXK4IlsJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "GXiQrxSKlwy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "D8XwXSlBl0B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "m85Efpr3mDfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Li0Iw_wFmJ2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "zC5Z18YLmT3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "kRa5BYznmOj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\",\n",
        "                        input_shape=(img_height,\n",
        "                                    img_width,\n",
        "                                    3)),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "kd1GFjgunC1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "bucrjeOQnKLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "fId-TA4YnxaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "b4NGrVI_oMsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "FBQU5RkSoRFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "3koaFbdfoTXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XIqLZLnvo3BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('model_CNN_2.h5')"
      ],
      "metadata": {
        "id": "Xywj2gBXr-SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "RszqdSVexDFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = 'RiceLeafs/validation/Hispa/IMG_20190419_131106.jpg'\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    img_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n",
        "\n",
        "print(\n",
        "    np.max(score)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix3HaDiJqMmh",
        "outputId": "6c2cf776-253e-42fe-a696-0f7572a502e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image most likely belongs to LeafBlast with a 99.82 percent confidence.\n",
            "0.9982146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------"
      ],
      "metadata": {
        "id": "D7m19wa67KxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deployment"
      ],
      "metadata": {
        "id": "19UX5lxSv4MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "Wj7Za6BcBH9a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model = tf.keras.models.load_model('model_CNN_2.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "# new_model.summary()"
      ],
      "metadata": {
        "id": "cQosZMnUxINk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 360\n",
        "img_width = 360"
      ],
      "metadata": {
        "id": "mrXgFtaf1cN6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path):\n",
        "    img = tf.keras.utils.load_img(\n",
        "    img_path, target_size=(img_height, img_width)\n",
        "    )\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "    predictions = model.predict(img_array)\n",
        "    predictions = predictions.tolist()[0]\n",
        "\n",
        "    classes = ['BrownSpot', 'Healthy', 'Hispa', 'LeafBlast']\n",
        "    results = {}\n",
        "\n",
        "    for key in classes:\n",
        "        for value in predictions:\n",
        "            results[key] = value\n",
        "            predictions.remove(value)\n",
        "            break\n",
        "\n",
        "    return results\n",
        "    "
      ],
      "metadata": {
        "id": "kIryi3ys3oOA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5f031wivywG",
        "outputId": "727d6db2-c482-44ee-caa8-e1d71412d087"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.6 MB 25.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 275 kB 58.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 59.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 141 kB 54.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 864 kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 44.1 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "EFWSC0kbw6x4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = gr.inputs.Image(shape=(360,360))\n",
        "label = gr.outputs.Label(num_top_classes=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qNJaLEm3ai1",
        "outputId": "be3c6c88-e463-4740-848e-0ff5c8d77538"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  \"Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\",\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0urJjoB8Skh",
        "outputId": "725f4f02-8839-407a-e348-85d4e278a883"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://21007.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://21007.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/routes.py\", line 256, in run_predict\n",
            "    fn_index, raw_input, username, session_state\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 630, in process_api\n",
            "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 546, in call_function\n",
            "    block_fn.fn, *processed_input, limiter=self.limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/to_thread.py\", line 32, in run_sync\n",
            "    func, *args, cancellable=cancellable, limiter=limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 490, in <lambda>\n",
            "    if len(self.output_components) == 1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 669, in run_prediction\n",
            "    prediction = self.fn(*processed_input)\n",
            "  File \"<ipython-input-7-f83d4ed7ff27>\", line 3, in predict_image\n",
            "    img_path, target_size=(img_height, img_width)\n",
            "NameError: name 'img_path' is not defined\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/routes.py\", line 256, in run_predict\n",
            "    fn_index, raw_input, username, session_state\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 630, in process_api\n",
            "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 546, in call_function\n",
            "    block_fn.fn, *processed_input, limiter=self.limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/to_thread.py\", line 32, in run_sync\n",
            "    func, *args, cancellable=cancellable, limiter=limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 490, in <lambda>\n",
            "    if len(self.output_components) == 1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 669, in run_prediction\n",
            "    prediction = self.fn(*processed_input)\n",
            "  File \"<ipython-input-7-f83d4ed7ff27>\", line 3, in predict_image\n",
            "    img_path, target_size=(img_height, img_width)\n",
            "NameError: name 'img_path' is not defined\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/routes.py\", line 256, in run_predict\n",
            "    fn_index, raw_input, username, session_state\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 630, in process_api\n",
            "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/blocks.py\", line 546, in call_function\n",
            "    block_fn.fn, *processed_input, limiter=self.limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/to_thread.py\", line 32, in run_sync\n",
            "    func, *args, cancellable=cancellable, limiter=limiter\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 490, in <lambda>\n",
            "    if len(self.output_components) == 1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gradio/interface.py\", line 669, in run_prediction\n",
            "    prediction = self.fn(*processed_input)\n",
            "  File \"<ipython-input-7-f83d4ed7ff27>\", line 3, in predict_image\n",
            "    img_path, target_size=(img_height, img_width)\n",
            "NameError: name 'img_path' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f6ff1fc4e10>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://21007.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}